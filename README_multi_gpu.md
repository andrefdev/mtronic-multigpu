# BGE-M3 Multi-GPU Optimized Processing

Sistema optimizado para generar embeddings BGE-M3 utilizando **4x L40S GPUs** con mÃ¡ximo rendimiento y carga concurrente a Qdrant.

## ğŸš€ CaracterÃ­sticas Principales

- **Multi-GPU Processing**: Utiliza las 4x L40S GPUs simultÃ¡neamente
- **Procesamiento Masivo**: Batches de 512 por GPU (2048 total)
- **Upload AsÃ­ncrono**: 16 workers para subida concurrente a Qdrant
- **Pipeline Optimizado**: 3 etapas de pipeline para mÃ¡ximo throughput
- **Monitoreo en Tiempo Real**: Monitor visual de GPUs y rendimiento
- **GestiÃ³n Inteligente de Memoria**: Auto-limpieza y optimizaciÃ³n VRAM
- **ConfiguraciÃ³n Adaptativa**: Ajustado especÃ­ficamente para L40S (48GB VRAM)

## ğŸ“Š Rendimiento Esperado

Con la configuraciÃ³n optimizada para 4x L40S:

- **Throughput**: 500-1000+ chunks/segundo
- **Batch Size Total**: 2048 embeddings simultÃ¡neos
- **VRAM Utilizada**: ~170GB de 192GB disponibles
- **Procesamiento**: 10-50 documentos/minuto (segÃºn tamaÃ±o)

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### 1. ConfiguraciÃ³n AutomÃ¡tica

```bash
# Ejecutar script de configuraciÃ³n
python setup_multi_gpu.py
```

Este script:
- âœ… Verifica hardware (4x L40S)
- âœ… Instala dependencias optimizadas
- âœ… Configura PyTorch con CUDA 12.1
- âœ… Crea archivos de configuraciÃ³n
- âœ… Prepara variables de entorno

### 2. ConfiguraciÃ³n Manual (Alternativa)

```bash
# Instalar PyTorch con CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Instalar dependencias
pip install -r requirements_multi_gpu.txt

# Cargar variables de entorno
source .env.multi_gpu  # Linux/Mac
# o importar manualmente en Windows
```

## ğŸš€ EjecuciÃ³n

### MÃ©todo 1: Launcher Optimizado (Recomendado)

```bash
python launch_multi_gpu.py
```

### MÃ©todo 2: EjecuciÃ³n Directa

```bash
python bge_m3_multi_gpu_optimized.py
```

### MÃ©todo 3: Con Monitor en Tiempo Real

```bash
# Terminal 1: Ejecutar procesamiento
python launch_multi_gpu.py

# Terminal 2: Monitor en tiempo real
python gpu_monitor.py
```

## ğŸ“ Archivos del Sistema

```
â”œâ”€â”€ bge_m3_multi_gpu_optimized.py    # Script principal optimizado
â”œâ”€â”€ requirements_multi_gpu.txt        # Dependencias
â”œâ”€â”€ setup_multi_gpu.py              # ConfiguraciÃ³n automÃ¡tica
â”œâ”€â”€ launch_multi_gpu.py              # Launcher optimizado
â”œâ”€â”€ gpu_monitor.py                   # Monitor en tiempo real
â”œâ”€â”€ multi_gpu_config.json            # ConfiguraciÃ³n del sistema
â”œâ”€â”€ .env.multi_gpu                   # Variables de entorno
â””â”€â”€ bge_m3_multi_gpu.log            # Logs de procesamiento
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Ajuste de Rendimiento

Editar `multi_gpu_config.json`:

```json
{
  "processing": {
    "batch_size_per_gpu": 512,      // Ajustar segÃºn VRAM disponible
    "num_workers_per_gpu": 4,       // Workers por GPU
    "async_upload_workers": 16,     // Workers de upload a Qdrant
    "pipeline_depth": 3,            // Profundidad del pipeline
    "memory_threshold": 0.85        // LÃ­mite de memoria (85%)
  }
}
```

### Variables de Entorno CrÃ­ticas

```bash
# 4 GPUs disponibles
CUDA_VISIBLE_DEVICES=0,1,2,3

# Optimizaciones CUDA
CUDA_LAUNCH_BLOCKING=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# CPU threads (32 cores / 4 GPUs)
OMP_NUM_THREADS=8
```

## ğŸ“Š Monitoreo y DiagnÃ³sticos

### Monitor en Tiempo Real

```bash
python gpu_monitor.py
```

**Funciones del Monitor:**
- ğŸ” Uso de GPU en tiempo real
- ğŸ“Š EstadÃ­sticas de memoria VRAM
- ğŸ”¥ Temperatura de GPUs
- âš¡ Velocidad de procesamiento
- ğŸ“ˆ Progreso de documentos
- âŒ Errores y warnings

**Controles:**
- `q`: Salir
- `r`: Refresh manual
- `c`: Limpiar pantalla

### Comandos de DiagnÃ³stico

```bash
# Verificar GPUs disponibles
nvidia-smi -L

# Monitoreo continuo de GPUs
nvidia-smi -l 1

# Verificar PyTorch + CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"

# Verificar memoria GPU
python -c "import torch; [print(f'GPU {i}: {torch.cuda.get_device_properties(i).total_memory//1024**3}GB') for i in range(torch.cuda.device_count())]"
```

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "CUDA out of memory"

```bash
# Reducir batch size por GPU
# En multi_gpu_config.json:
"batch_size_per_gpu": 256  # Reducir de 512
```

### GPUs no detectadas

```bash
# Verificar drivers NVIDIA
nvidia-smi

# Verificar CUDA_VISIBLE_DEVICES
echo $CUDA_VISIBLE_DEVICES

# Reinstalar PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Rendimiento bajo

1. **Verificar utilizaciÃ³n GPU** (debe estar >80%)
2. **Aumentar batch_size_per_gpu** si hay VRAM disponible
3. **Verificar red**: Qdrant debe estar en red rÃ¡pida
4. **Verificar CPU**: No debe estar al 100%
5. **Verificar I/O**: MongoDB debe responder rÃ¡pido

### Errores de conexiÃ³n Qdrant

```python
# Aumentar workers y timeout en config
"qdrant": {
    "batch_size": 500,           # Reducir si hay errores
    "connection_pool_size": 10,  # Reducir conexiones
    "timeout": 60                # Aumentar timeout
}
```

## ğŸ“ˆ Optimizaciones por Hardware

### Para 4x L40S (192GB VRAM total)

```json
{
  "processing": {
    "batch_size_per_gpu": 512,
    "memory_threshold": 0.85,
    "pipeline_depth": 3
  }
}
```

### Para menos VRAM (ej: 4x RTX 4090)

```json
{
  "processing": {
    "batch_size_per_gpu": 128,
    "memory_threshold": 0.75,
    "pipeline_depth": 2
  }
}
```

### Para mÃ¡s GPUs (ej: 8x H100)

```json
{
  "system": {
    "num_gpus": 8
  },
  "processing": {
    "batch_size_per_gpu": 1024,
    "async_upload_workers": 32
  }
}
```

## ğŸš¨ Mejores PrÃ¡cticas

### Antes de Ejecutar

1. âœ… Verificar que no hay otros procesos usando GPUs
2. âœ… Confirmar conexiÃ³n estable a Qdrant y MongoDB
3. âœ… Verificar espacio en disco para logs
4. âœ… Configurar lÃ­mites de temperatura GPU (opcional)

### Durante EjecuciÃ³n

1. ğŸ” Monitorear temperatura GPUs (<80Â°C recomendado)
2. ğŸ“Š Verificar utilizaciÃ³n GPU (>80% ideal)
3. ğŸ”„ Verificar progreso en logs
4. ğŸ’¾ Monitorear espacio en disco

### DespuÃ©s de Ejecutar

1. ğŸ§¹ Limpiar memoria GPU: `torch.cuda.empty_cache()`
2. ğŸ“‹ Revisar estadÃ­sticas finales en logs
3. âœ… Verificar datos subidos a Qdrant
4. ğŸ“Š Analizar rendimiento para futuros ajustes

## ğŸ“ Soporte y Debugging

### Logs Detallados

```bash
# Ver logs en tiempo real
tail -f bge_m3_multi_gpu.log

# Buscar errores
grep -i error bge_m3_multi_gpu.log

# EstadÃ­sticas de rendimiento
grep -i "chunks/s\|docs/s" bge_m3_multi_gpu.log
```

### InformaciÃ³n del Sistema

```bash
# Script de diagnÃ³stico completo
python setup_multi_gpu.py
```

### ConfiguraciÃ³n de Desarrollo

Para desarrollo y testing:

```json
{
  "processing": {
    "batch_size_per_gpu": 32,
    "pipeline_depth": 1,
    "async_upload_workers": 4
  }
}
```

---

## ğŸ¯ Resumen de Comandos RÃ¡pidos

```bash
# ConfiguraciÃ³n inicial
python setup_multi_gpu.py

# EjecuciÃ³n estÃ¡ndar
python launch_multi_gpu.py

# Con monitoreo
python gpu_monitor.py  # Terminal separado

# Verificar GPUs
nvidia-smi -l 1

# Ver logs
tail -f bge_m3_multi_gpu.log
```

**Â¡Tu sistema 4x L40S estÃ¡ optimizado para procesar miles de documentos por hora!** ğŸš€
